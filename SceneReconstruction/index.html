<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
        content="Generalizable 3D Scene Reconstruction via Divide and Conquer from a Single View" />
    <title>Generalizable 3D Scene Reconstruction via Divide and Conquer from a Single View</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="css/custom.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <script async src="https://cdn.jsdelivr.net/npm/es-module-shims@1.6.3/dist/es-module-shims.js"></script>
    <script type="importmap">
    {
        "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.148.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.148.0/examples/jsm/"
        }
    }

    </script>
    <script type="module" src="./js/visualizer.js"></script>

    <style>
        body {
            background: #ffffff no-repeat fixed top left;
            font-family: 'Open Sans', sans-serif;
        }
    </style>

</head>

<!-- cover -->
<section>
    <div class="jumbotron text-center mt-0">
        <div class="container">
            <div class="row">
                <div class="col">
                    <h2 style="font-size:30px;">Generalizable 3D Scene Reconstruction via <br> Divide and Conquer from a
                        Single View</h2>
                    <h4 style="color:#6e6e6e;"> arXiv 2024</h4>
                    <hr>
                    <h6><a href="https://andreeadogaru.github.io/" target="_blank">Andreea
                            Dogaru</a>&nbsp;&nbsp;&nbsp;&nbsp;
                        Mert Özer
                        </a>&nbsp;&nbsp;&nbsp;&nbsp;
                        <a href="https://eggerbernhard.ch/" target="_blank">Bernhard Egger</a>
                    </h6>
                    <p>Friedrich-Alexander-Universität Erlangen-Nürnberg
                    </p>

                    <div class="row justify-content-center">
                        <div class="column">
                            <p class="mb-5"><a class="btn btn-large btn-light"
                                    href="https://arxiv.org/pdf/2209.15511.pdf" role="button" target="_blank">
                                    <i class="fa fa-file"></i> Paper</a></p>
                        </div>
                        <div class="column">
                            <p class="mb-5"><a class="btn btn-large btn-light" id="code_soon"
                                    href="https://github.com/AndreeaDogaru/SphereGuided" role="button" target="_blank"
                                    disabled=1>
                                    <i class="fa fa-github-alt"></i> Code</a></p>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </div>
    </div>
</section>

<!-- abstract -->
<section>
    <div class="container">
        <div class="row">
            <div class="col-12 text-center">
                <h3>Abstract</h3>
                <hr style="margin-top:0px">
                <div><img class="img-fluid" src="images/teaser.png" alt=""></div>
                <br>
                <p class="text-justify">
                    Single-view 3D reconstruction is currently approached from two dominant
                    perspectives: reconstruction of scenes with limited diversity using 3D data supervision or
                    reconstruction of diverse singular objects using large image priors. However, real-world
                    scenarios are far more complex and exceed the capabilities of these methods. We
                    therefore propose a hybrid method following a divide-and-conquer strategy. We first
                    process the scene holistically, extracting depth and semantic information, and then
                    leverage a single-shot object-level method for the detailed reconstruction of
                    individual components. By following a compositional processing approach, the overall
                    framework achieves full reconstruction of complex 3D scenes from a single image. We
                    purposely design our pipeline to be highly modular by carefully integrating specific
                    procedures for each processing step, without requiring an end-to-end training of the
                    whole system. This enables the pipeline to naturally improve as future methods can
                    replace the individual modules.
                </p>
            </div>
        </div>
    </div>
</section>
<br>

<section>
    <div class="container">
        <div class="row">
            <div class="col-12 text-center">
                <h2>Method</h2>
                <hr style="margin-top:0px">
            </div>
            <p class="text-justify">
                Our method takes as input a single RGB image and predicts the full 3D scene reconstruction represented as a collection of triangle meshes. First, we parse the image of the scene by finding the composing instances, and estimating the depth and camera parameters. Then, we separate the identified entities in stuff (amorphus shapes) and things (characteristic shapes).
                To recover the full view of each object, we perform amodal completion on the masked crops of the instances.
                Each object is reconstructed individually in a normalized space and aligned to the view space using the scene layout guides from the depth map. Importantly, we address the differences in focal length, principal point, and camera-to-object distance between the two spaces through reprojection. Finally, we model the background as the surface that approximates the stuff entities collectively.
            </p>
            <div><img class="img-fluid" src="images/method.png" alt=""></div>
        </div>
    </div>
</section>

<br> 
<br> 

<section>
    <div class="container">
        <div class="row">
            <div class="col-12 text-center">
                <h2>Results</h2>
                <hr style="margin-top:0px">
            </div>
        </div>

        <br>

        <div class="col text-justify">
            <h4 style="color:grey;">Interactive visualization</h4>
        </div>

        <section id="loading-screen">

            <div id="loader"></div>

        </section>

        <div class="row">
            <div class="col text-center">
                <h3>Input image</h3>
            </div>
            <div class="col text-center">
                <h3>Reconstructed scene</h3>
            </div>
        </div>

        <div class="row" id="vis">
            <div class="col text-center">
                <img class="img-fluid" id="scene_img" alt="">
            </div>
            <div class="col text-center">
                <canvas id="canvas_scene"> </canvas>
            </div>
            <div class="loading-overlay">
                <div class="loading-spinner"></div>
                <div class="loading-progress"></div>
            </div>
        </div>

        <br>

        <div class="row">
            <div class="col text-center d-flex align-items-center justify-content-center">
                <span style="font-size: 2em;">Scenes</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
                <input type="image" src="scenes/1/input.png" class="img_button" id="bton_s1"/>
                <input type="image" src="scenes/2/input.png" class="img_button" id="bton_s2"/>
                <input type="image" src="scenes/3/input.png" class="img_button" id="bton_s3"/>
                <input type="image" src="scenes/4/input.png" class="img_button" id="bton_s4"/>
                <input type="image" src="scenes/5/input.png" class="img_button" id="bton_s5"/>
            </div>
        </div>
    </div>
</section>
<br>
<!-- citing -->
<div class="container">
    <div class="row ">
        <div class="col-12">
            <h3>Citation</h3>
            <hr style="margin-top:0px">
            <pre style="background-color: #f0f3fb;padding: 1.25em 1.5em"><code>
    @article{Dogaru2024Scene,
        TODO
    }</code>
            </pre>
        </div>
    </div>
</div>

<br>

<!-- ack -->
<div class="container">
    <div class="row ">
        <div class="col-12">
            <h3>Acknowledgement</h3>
            <hr style="margin-top:0px">
            <p class="text-justify">
                This work was funded by the German Federal Ministry of Education and Research
                (BMBF), FKZ: 01IS22082 (IRRW). The authors are responsible for the content of this
                publication. The authors gratefully acknowledge the scientific support and HPC resources
                provided by the Erlangen National High Performance Computing Center (NHR@FAU) of the
                Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU) under the NHR project b112dc IRRW. NHR funding
                is provided by federal and Bavarian state authorities. NHR@FAU hardware is partially
                funded by the German Research Foundation (DFG) – 440719683.
            </p>
        </div>
    </div>
</div>

<footer class="text-center" style="margin-bottom:10px; font-size: medium;">
    <hr>
    Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the <a
        href="https://lioryariv.github.io/idr/" target="_blank">website template</a>.
</footer>
</body>

</html>