<!doctype html>
<html>

<head>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Andreea Dogaru's Homepage</title>
  <link href="css/about.css" rel="stylesheet" type="text/css">
  <style type="text/css">
  </style>
</head>

<body alink="#282727" vlink="#9b9b9b" link="#9b9b9b">
  <!-- Header content -->
  <header>
    <div class="profilePhoto">
      <!-- Profile photo -->
      <img src="images/profile_pic.png" alt="sample" width="259">
    </div>
    <!-- Identity details -->
    <section class="profileHeader">
      <h1>Andreea Dogaru</h1>
      <h3>PhD Candidate</h3>
      <hr>
      <p>I am a researcher in the <a href="https://twitter.com/cogcovi" target="_blank">
          Cognitive Computer Vision Lab</a> within the <a href="https://www.lgdv.tf.fau.de/" target="_blank">
          Chair of Visual Computing</a> at <a href="https://www.fau.de/" target="_blank">
          Friedrich-Alexander-Universität Erlangen-Nürnberg</a>, advised by <a href="https://eggerbernhard.ch/"
          target="_blank">Prof. Dr. Bernhard Egger</a>.
        <br> My research interests are within Computer Vision and Computer Graphics fields, with a focus on Neural Scene
        Representations, 3D Reconstruction, and Shape Modelling.
        <br> Before joining FAU, I obtained my M. Sc. in Data Science from the
        <a href="https://www.skoltech.ru/en/" target="_blank">Skolkovo Institute of Science and Technology</a>
        and collaborated with <a href="https://research.samsung.com/" target="_blank">
          Samsung AI Center</a> on 3D Computer Vision applications.
        <br>
      </p>
    </section>
    <!-- Links to Social network accounts -->
    <aside class="socialNetworkNavBar">
      <div class="socialNetworkNav">
        <!-- Add a Anchor tag with nested img tag here -->
        <a href="mailto:andreea.dogaru@fau.de">
          <img src="images/mail.png" alt="sample" width="30"></a>
      </div>
      <div class="socialNetworkNav">
        <!-- Add a Anchor tag with nested img tag here -->
        <a href="https://github.com/AndreeaDogaru" target="_blank">
          <img src="images/github.png" alt="sample" width="30"></a>
      </div>
      <div class="socialNetworkNav">
        <a href="https://scholar.google.com/citations?user=HF1pWaAAAAAJ&hl=en" target="_blank">
          <!-- Add a Anchor tag with nested img tag here -->
          <img src="images/gscholar.png" alt="sample" width="30">
        </a>
      </div>
      <div class="socialNetworkNav">
        <!-- Add a Anchor tag with nested img tag here -->
        <a href="https://twitter.com/andreead_a" target="_blank">
          <img src="images/twitter.png" alt="sample" width="30"></a>
      </div>

      <div class="socialNetworkNav">
        <a href="https://www.linkedin.com/in/andreea-dogaru" target="_blank">
          <img src="images/linkedin.png" alt="sample" width="30"> </a>
      </div>
    </aside>
  </header>
  <!-- content -->
  <section class="mainContent">
    <!-- Contact details -->

    <!-- Previous experience details -->

    <section class="section2">
      <h2 class="sectionTitle">Publications</h2>
      <hr class="sectionTitleRule">
      <hr class="sectionTitleRule2">

      <!-- NeuralHaircut  -->
      <div class="sectionContent" style="padding:0px;vertical-align:middle">
            <video autoplay muted loop playsinline style="width: 100%; height: 100%;">
              <source src="images/jenya_teaser3.mp4" type="video/mp4">
            </video>
      </div>
      <section class="section2Content">
        <h2 class="sectionContentTitle"> Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction</h2>
        <h3 class="sectionContentSubTitle">
          Vanessa&nbsp;Sklyarova,
          Jenya&nbsp;Chelishev,
          <i>Andreea&nbsp;Dogaru</a></i>,
          Igor&nbsp;Medvedev,
          <a href="https://egorzakharov.github.io/" target="_blank">Egor&nbsp;Zakharov</a>,
          <a href="https://scholar.google.com/citations?user=gYYVokYAAAAJ&hl=en"
            target="_blank">Victor&nbsp;Lempitsky</a>
        </h3>
        <h3 class="sectionContentSubTitle">International Conference on Computer Vision - <b
          style="color:purple">ICCV&nbsp;2023</b></h3>
      </section>
      <aside class="externalResourcesNav">

        <div class="dropdown"><a href="https://samsunglabs.github.io/NeuralHaircut/"
            target="_blank">Project Page</a></div>
        <div class="dropdown"> <span>Abstract</span>
          <div class="dropdown-content">
            <p style="text-align:left;"> We propose an approach that can accurately reconstruct hair geometry at a
              strand level from a monocular video or multi-view images captured in uncontrolled lighting conditions. Our
              method has two stages, with the first stage performing joint reconstruction of coarse hair and bust shapes
              and hair orientation using implicit volumetric representations. The second stage then estimates a
              strand-level hair reconstruction by reconciling in a single optimization process the coarse volumetric
              constraints with hair strand and hairstyle priors learned from the synthetic data. To further increase the
              reconstruction fidelity, we incorporate image-based losses into the fitting process using a new
              differentiable renderer. The combined system, named Neural Haircut, achieves high realism and
              personalization of the reconstructed hairstyles. </p>
          </div>
        </div>
        <div class="dropdown"><a href="https://arxiv.org/pdf/2306.05872.pdf" target="_blank">Paper</a>
        </div>
        <div class="dropdown"><a href="https://github.com/SamsungLabs/NeuralHaircut"
          target="_blank">Code</a></div>
      </aside>

    </section>

      <br>
      <br>
      <br>
      <section class="section2">
      <!-- SphereGuided  -->
      <div class="sectionContent" style="padding:0px;vertical-align:middle">
            <img src="SphereGuided/images/teaser.jpg" style="height: 100%; width: 100%; object-fit: contain" alt="">
      </div>
      <section class="section2Content">
        <h2 class="sectionContentTitle"> Sphere-Guided Training of Neural Implicit Surfaces </h2>
        <h3 class="sectionContentSubTitle">
          <i>Andreea&nbsp;Dogaru</i>,
          <a href="https://reality.tf.fau.de/staff/t.ardelean.html" target="_blank">Andrei-Timotei&nbsp;Ardelean</a>,
          <a href="https://scholar.google.com/citations?user=aJyxXoMAAAAJ&hl=en"
            target="_blank">Savva&nbsp;Ignatyev</a>,
          <a href="https://egorzakharov.github.io/" target="_blank">Egor&nbsp;Zakharov</a>,
          <a href="https://faculty.skoltech.ru/people/evgenyburnaev" target="_blank">Evgeny&nbsp;Burnaev</a>
        </h3>
        <h3 class="sectionContentSubTitle">Conference on Computer Vision and Pattern Recognition - <b
            style="color:purple">CVPR&nbsp;2023</b></h3>
      </section>
      <aside class="externalResourcesNav">

        <div class="dropdown"><a href="https://andreeadogaru.github.io/SphereGuided/"
            target="_blank">Project Page</a></div>
        <div class="dropdown"> <span>Abstract</span>
          <div class="dropdown-content">
            <p style="text-align:left;"> In recent years, neural distance functions trained via volumetric ray marching
              have been widely adopted for multi-view 3D reconstruction. These methods, however, apply the ray marching
              procedure for the entire scene volume, leading to reduced sampling efficiency and, as a result, lower
              reconstruction quality in the areas of high-frequency details. In this work, we address this problem via
              joint training of the implicit function and our new coarse sphere-based surface reconstruction. We use the
              coarse representation to efficiently exclude the empty volume of the scene from the volumetric ray
              marching procedure without additional forward passes of the neural surface network, which leads to an
              increased fidelity of the reconstructions compared to the base systems. We evaluate our approach by
              incorporating it into the training procedures of several implicit surface modeling methods and observe
              uniform improvements across both synthetic and real-world datasets.</p>
          </div>
        </div>
        <div class="dropdown"><a href="https://arxiv.org/pdf/2209.15511.pdf" target="_blank">Paper</a>
        </div>
        <div class="dropdown"><a href="https://github.com/AndreeaDogaru/SphereGuided"
            target="_blank">Code</a></div>
      </aside>

      <br>

      <!-- Replicate the above Div block to add more title and company details -->
    </section>
    <hr>

  </section>
  <footer>
    <p class="footerDisclaimer">Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the
      website template.<br>
      Icons included in the page are from <a href="https://www.flaticon.com/authors/pixel-perfect"
        target="_blank">Flaticon</a>.<span></span></p>
    <p class="footerNote"></p>
  </footer>
</body>

</html>